{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) MLPs are useful to solve problems which often allows approximate solutions for extremely complex problems like fitness approximation, can be used to create mathematical models by regression analysis. MLPs make good classifier algorithms for complex problems too .\n",
    "\n",
    "MLPs were a popular machine learning solution finding applications in diverse fields such as speech recognition, image recognition, and machine translation software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Build a MLP the PyTorch way:\n",
    "a. Define a class called Net_0 which inherits from Module\n",
    "b. In the __init__() method, define the parameters for the two hidden layers:\n",
    "i. Fully Connected Hidden Layer (50 input features, 20 output features)\n",
    "ii. Fully Connected Hidden Layer (20 output features)\n",
    "iii. Output Layer (3 output features)\n",
    "c. In the forward() method, do the forward step.\n",
    "Use the Sigmoid function for the activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_0(\n",
       "  (fc1): Linear(in_features=50, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (output): Linear(in_features=20, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5) required imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #for activation function\n",
    "\n",
    "\n",
    "# Define the class called NET_0 which inherits from nn.Module\n",
    "\n",
    "\n",
    "\n",
    "class Net_0(nn.Module):\n",
    "    def __init__(self,n_hidden1=20):\n",
    "        super(Net_0,self).__init__()\n",
    "\n",
    "        self.fc1=nn.Linear(50,n_hidden1)\n",
    "        self.fc2=nn.Linear(20,20)\n",
    "        self.output=nn.Linear(20,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.sigmoid(self.fc1(x))\n",
    "        x=F.sigmoid(self.fc2(x))\n",
    "        x=self.output(x)\n",
    "        return x\n",
    "\n",
    "Net_0(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Build a MLP the PyTorch way:\n",
    "a. Define a class called Net_1 which inherits from Module\n",
    "b. In the __init__() method, define the parameters for the four hidden layers:\n",
    "i. Fully Connected Hidden Layer (700 input features, 300 output features)\n",
    "ii. Fully Connected Hidden Layer (125 output features)\n",
    "iii. Fully Connected Hidden Layer (50 output features)\n",
    "iv. Output Layer (10 output features)\n",
    "c. In the forward() method, do the forward step.\n",
    "Use the ReLU function for the activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_1(\n",
       "  (fc1): Linear(in_features=700, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=125, bias=True)\n",
       "  (fc3): Linear(in_features=125, out_features=50, bias=True)\n",
       "  (output): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the class called Net_1 which inherits from nn.Module# \n",
    "\n",
    "\n",
    "\n",
    "class Net_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_1,self).__init__()\n",
    "        self.fc1=nn.Linear(700,300)\n",
    "        self.fc2=nn.Linear(300,125)\n",
    "        self.fc3=nn.Linear(125,50)\n",
    "        self.output=nn.Linear(50,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=self.output(x)\n",
    "        return x\n",
    "        \n",
    "Net_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Build a MLP the PyTorch way:\n",
    "a. Define a class called Net_2 which inherits from Module\n",
    "b. In the __init__() method, define the parameters for the two fully connected layers:\n",
    "i. Fully Connected Hidden Layer (input_size input features, 20 output features)\n",
    "ii. Fully Connected Hidden Layer (20 output features)\n",
    "iii. Output Layer (output_size output feature)\n",
    "c. In the forward() method, do the forward step.\n",
    "Use the Sigmoid function for the activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_2(\n",
       "  (fc1): Linear(in_features=22, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (output): Linear(in_features=20, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Net_2(nn.Module):\n",
    "    def __init__(self,input_size=30,output_size= 5):\n",
    "        super(Net_2,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,20)\n",
    "        self.fc2=nn.Linear(20,20)\n",
    "        self.output=nn.Linear(20,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.sigmoid(self.fc1(x))\n",
    "        x=F.sigmoid(self.fc2(x))\n",
    "        x=self.output(x)\n",
    "        return x\n",
    "        \n",
    "Net_2(22,12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Build a MLP the PyTorch way:\n",
    "a. Define a class called Net_3 which inherits from Module\n",
    "b. In the __init__() method, define the parameters for the two fully connected layers:\n",
    "i. Fully Connected Hidden Layer (input_size input features, n output features)\n",
    "ii. Fully Connected Hidden Layer (m output features)\n",
    "iii. Output Layer (output_size output feature)\n",
    "c. In the forward() method, do the forward step.\n",
    "Use the ReLU function for the activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_3(\n",
       "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=3, bias=True)\n",
       "  (output): Linear(in_features=3, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net_3(nn.Module):\n",
    "    def __init__(self,input_size=30,output_size=5,n=30,m=10):\n",
    "        super(Net_3,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,n)\n",
    "        self.fc2=nn.Linear(n,m)\n",
    "        self.output=nn.Linear(m,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.output(x)\n",
    "        return x\n",
    "        \n",
    "Net_3(20,30,10,3)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2437014e73cc64fd84e82556bba012ba1aea65d4a95f4ac0ef674fe6ea933c97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
